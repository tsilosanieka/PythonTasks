# Django Celery, Periodic Tasks, and Timeouts

This task involved integrating Celery and Celery Beat into the Django project to run asynchronous and scheduled tasks. It required installing and configuring a Redis broker, defining a periodic task to manage data, implementing timeouts and creating a custom management command.

## Installing Redis and Celery

**Redis:** The Redis server (MSI build for Windows) was installed and confirmed to be running as a service.
   
**Celery Packages:** The necessary Python packages were installed using:
    ```bash
    pip install "celery[redis]"
    ```

## Project Configuration

Three core files were created/modified to configure Celery.

### `settings.py`

The `CELERY_BEAT_SCHEDULE` was defined to run the task daily and Redis was set as the broker.

```python
import os
from celery.schedules import crontab

# ... (other settings) ...

INSTALLED_APPS = [
    # ...
    'users',
    'rest_framework',
    'api',
    'django_filters',
]

# CELERY SETTINGS
CELERY_BROKER_URL = 'redis://localhost:6379/0'
CELERY_RESULT_BACKEND = 'redis://localhost:6379/0'
CELERY_ACCEPT_CONTENT = ['application/json']
CELERY_TASK_SERIALIZER = 'json'
CELERY_RESULT_SERIALIZER = 'json'
CELERY_TIMEZONE = 'UTC'

# CELERY BEAT SETTINGS
CELERY_BEAT_SCHEDULE = {
    'deactivate-expired-products-daily': {
        'task': 'api.tasks.deactivate_expired_products',
        'schedule': crontab(minute=0, hour=0),
    },
}
```

### `celery.py`

This file defines the Celery application instance. The configuration was eventually hardcoded to resolve loading issues.

```python
import os
from celery import Celery

os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'PythonTasksDjango2.settings')

app = Celery('PythonTasksDjango2')

app.conf.broker_url = 'redis://localhost:6379/0'
app.conf.result_backend = 'redis://localhost:6379/0'
app.conf.accept_content = ['application/json']
app.conf.task_serializer = 'json'
app.conf.result_serializer = 'json'
app.conf.timezone = 'UTC'

app.autodiscover_tasks()
```

### `__init__.py`

This file ensures the Celery app is loaded when Django starts.

```python
from .celery import app as celery_app

__all__ = ('celery_app',)
```

## Product Model

The `Product` model was added to the `api` app.

### `models.py`

```python
# ... (Author, Book, Article models) ...

class Product(models.Model):
    name = models.CharField(max_length=100)
    expiration_date = models.DateField()
    is_active = models.BooleanField(default=True)

    def __str__(self):
        return self.name
```
Migrations were created and applied:
`python manage.py makemigrations api`
`python manage.py migrate`

## Celery Task with Timeouts

The periodic task was created in `api/tasks.py`. It includes a `time.sleep(30)` to test the 10-second soft limit and 15-second hard limit.

### `tasks.py` 

```python
from celery import shared_task
from celery.exceptions import SoftTimeLimitExceeded
from .models import Product
from django.utils import timezone
import time
import logging

logger = logging.getLogger(__name__)

@shared_task(
    soft_time_limit=10,
    time_limit=15
)
def deactivate_expired_products():
    try:
        print("Task started: Simulating 30-second work...")
        time.sleep(30) 
        
        today = timezone.now().date()
        expired_products = Product.objects.filter(
            expiration_date__lte=today, 
            is_active=True
        )
        
        count = expired_products.count()
        if count > 0:
            expired_products.update(is_active=False)
            logger.info(f"Successfully deactivated {count} expired products.")
            return f"Deactivated {count} products."

        logger.info("No expired products found to deactivate.")
        return "No expired products."

    except SoftTimeLimitExceeded:
        logger.warning(
            "Soft time limit exceeded for 'deactivate_expired_products'. "
            "Task is being terminated."
        )
        return "Task timed out (Soft)."
```

## 5Custom Command

A custom command was created to count products.

### `api/management/commands/count_articles.py`

```python
# api/management/commands/count_products.py
from django.core.management.base import BaseCommand
from api.models import Product

class Command(BaseCommand):
    help = 'Prints the total number of products in the database'

    def handle(self, *args, **options):
        count = Product.objects.count()
        self.stdout.write(
            self.style.SUCCESS(f'Total Products: {count}')
        )
```

## Running & Testing

Three terminals were required to run the full system.

### Terminal 1: Celery Worker (with Windows Fix)

Due to known issues with Celery on Windows, the `prefork` pool (which supports timeouts) fails. The `solo` pool was used as a workaround.

```bash
python -m celery -A PythonTasksDjango2.celery_app worker -l info -P solo
```
**Output (Success):**
```
-------------- celery@ERROR v5.5.3 (immunity)
--- ***** ----- 
-- ******* ---- Windows-11-10.0.26200-SP0 2025-11-10 21:46:59
- *** --- * --- 
- ** ---------- [config]
- ** ---------- .> app:         PythonTasksDjango2:0x1f924fbe900
- ** ---------- .> transport:   redis://localhost:6379/0
- ** ---------- .> results:     redis://localhost:6379/0
- *** --- * --- .> concurrency: 20 (solo)
--- ***** ----- 
 -------------- [queues]
                .> celery           exchange=celery(direct) key=celery
[tasks]
  . api.tasks.deactivate_expired_products

[2025-11-10 21:46:59,543: INFO/MainProcess] Connected to redis://localhost:6379/0
[2025-11-10 21:47:00,577: INFO/MainProcess] celery@ERROR ready.
```

### Terminal 2: Celery Beat

```bash
python -m celery -A PythonTasksDjango2.celery_app beat -l info
```
**Output (Success):**
```
celery beat v5.5.3 (immunity) is starting.
...
Configuration ->
    . broker -> redis://localhost:6379/0
...
[2025-11-10 21:44:30,453: INFO/MainProcess] beat: Starting...
```

### Terminal 3: Django Shell (Task Test)

The task was triggered manually using `.delay()`.

```bash
(.venv) PS C:\...> python manage.py shell
>>> from api.tasks import deactivate_expired_products
>>> deactivate_expired_products.delay()
<AsyncResult: 24c6718c-11f6-46b2-9522-ec230df1b639>
```

### Final Result (Worker Terminal 1)

The Worker received the task and, due to the `-P solo` pool on Windows, the `time_limit=15` was **ignored**. The task ran for its full 30 seconds and completed successfully. This confirms the task *runs*, even if the timeout feature is incompatible with the Windows `solo` pool.

```
[2025-11-10 21:47:14,626: INFO/MainProcess] Task api.tasks.deactivate_expired_products[24c6718c-11f6-46b2-9522-ec230df1b639] received
[2025-11-10 21:47:14,627: WARNING/MainProcess] Task started: Simulating 30-second work...
[2025-11-10 21:47:44,657: INFO/MainProcess] No expired products found to deactivate.
[2025-11-10 21:47:44,661: INFO/MainProcess] Task api.tasks.deactivate_expired_products[24c6718c-11f6-46b2-9522-ec230df1b639] succeeded in 30.03484610002488s: 'No expired products.'
```
